name: Zip Bomb Upload Workflow

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  unzip-and-upload:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Install unzip utility
      - name: Install unzip
        run: sudo apt-get install -y unzip

      # Step 3: List files in the ZIP
      - name: List files in ZIP
        id: list_files
        run: |
          unzip -l zbbig2.zip | awk '/assets\// {print $NF}' > file_list.txt
          echo "Successfully listed files to file_list.txt."
          cat file_list.txt

      # Step 4: Unzip in parallel batches, but serialize Git operations
      - name: Unzip in parallel batches and commit
        run: |
          # Define the batch size for parallel processing
          batch_size=5
          # Read file list into an array
          mapfile -t files < file_list.txt

          # Function to unzip files
          extract_file() {
            local file="$1"
            if unzip -o "zbbig2.zip" "$file"; then
              echo "[Success] Extracted: $file"
            else
              echo "[Error] Failed to extract: $file" >&2
            fi
          }

          # Function to commit and push files (serialize this part)
          commit_and_push() {
            local file="$1"
            git config --global user.name 'github-actions[bot]'
            git config --global user.email 'github-actions[bot]@users.noreply.github.com'
            if [ -f "$file" ]; then
              git add "$file"
              git commit -m "Add extracted file: $file"
              if git push; then
                echo "[Success] Pushed: $file"
                rm "$file" || echo "[Warning] Failed to delete: $file"
              else
                echo "[Error] Push failed for: $file" >&2
              fi
            else
              echo "[Error] File not found after extraction: $file" >&2
            fi
          }

          # Export the functions so xargs can access them
          export -f extract_file commit_and_push
          
          total_files="${#files[@]}"
          index=0
          while [ $index -lt $total_files ]; do
            echo "Processing batch starting from index $index..."
            batch_files=("${files[@]:index:batch_size}")

            # Extract files in parallel
            for file in "${batch_files[@]}"; do
              bash -c 'extract_file "$@"' _ "$file" &
            done

            wait  # Wait for all background processes to finish

            # Commit and push files sequentially to avoid conflicts
            for file in "${batch_files[@]}"; do
              bash -c 'commit_and_push "$@"' _ "$file"
            done

            index=$((index + batch_size))  # Increment index by batch size
          done

      # Step 5: Clean up
      - name: Clean up
        run: rm -f file_list.txt
